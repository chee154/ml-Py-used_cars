{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project 1 - Used Cars in the USA - SVM & LR Classification\n",
    "#### By: David Wei, Sophia Wu, Dhruba Dey, Queena Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this section we will continue using our used car dataset and be building out a classification model using Logistic Regression (LR) and Support Vector Machines (SVM). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing libraries and reading in file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #ignoring warnings\n",
    "import missingno as msno\n",
    "\n",
    "#plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotnine.data import economics\n",
    "from plotnine import ggplot, aes, geom_line\n",
    "\n",
    "#general sklearn libraries\n",
    "from scipy.stats import trim_mean, kurtosis\n",
    "from scipy.stats.mstats import mode, gmean, hmean\n",
    "import ptitprince as pt\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.model_selection as cross_validation\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler #for scaling\n",
    "\n",
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience and clarity, we have exported all of the data tidying and cleaning we have applied to our original dataset from our initial EDA workbook as an importable file. This will allow us to simply pick up on where we left off without cluttering our notebook with all prior code. For reference, please refer to the following [github link](https://github.com/chee154/ml-Py-used_cars/blob/main/Used_Car_Lab_1_DataVisualization.ipynb) where all work has been contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Records: 697989\n",
      "# of Columns: 18\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(r'E:\\Data Files\\used_cars_data_cleaned.csv')\n",
    "print('# of Records: '+str(len(df_raw)))\n",
    "print('# of Columns: '+str(df_raw.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Tidying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addressing Empty Values\n",
    "<b>NOTE</b>: First time running the logistic regression model returned an error: \n",
    "<br>\n",
    "*ValueError: Input contains NaN, infinity or a value too large for dtype('float64').*\n",
    "<br>\n",
    "Therefore, we will fix this by once again removing any strangling NA records from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697881\n",
      "# of Records Removed: 108\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_raw.copy()\n",
    "df_cleaned = df_cleaned.dropna()\n",
    "print(len(df_cleaned))\n",
    "print('# of Records Removed: '+str(len(df_raw)-len(df_cleaned)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up final dataframe\n",
    "After the initial EDA, we will make the appropriate adjustments to our dataset based on our findings. To begin, let's get look at the relationship between **'length'** and **'height'** due to it's high correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "they are the same... dropping one\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "df_test = df_cleaned.copy()\n",
    "print(df_test.shape[1])\n",
    "\n",
    "if df_test['length'].equals(df_test['height']) == True:\n",
    "    print('they are the same... dropping one')\n",
    "    df_test = df_test.drop(columns='height')\n",
    "    print(df_test.shape[1])\n",
    "else: \n",
    "    print('they are not the same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['rank']=df_test['price'].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['rank_pct']= df_test['price'].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>rank</th>\n",
       "      <th>rank_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357243</th>\n",
       "      <td>484.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357242</th>\n",
       "      <td>484.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357218</th>\n",
       "      <td>484.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345470</th>\n",
       "      <td>490.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82576</th>\n",
       "      <td>495.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218024</th>\n",
       "      <td>1244996.0</td>\n",
       "      <td>697877.0</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501812</th>\n",
       "      <td>1499999.0</td>\n",
       "      <td>697878.0</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56656</th>\n",
       "      <td>2698500.0</td>\n",
       "      <td>697879.0</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42212</th>\n",
       "      <td>3195000.0</td>\n",
       "      <td>697880.0</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340170</th>\n",
       "      <td>3299995.0</td>\n",
       "      <td>697881.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697881 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            price      rank  rank_pct\n",
       "357243      484.0       2.0  0.000003\n",
       "357242      484.0       2.0  0.000003\n",
       "357218      484.0       2.0  0.000003\n",
       "345470      490.0       4.0  0.000006\n",
       "82576       495.0      11.5  0.000016\n",
       "...           ...       ...       ...\n",
       "218024  1244996.0  697877.0  0.999994\n",
       "501812  1499999.0  697878.0  0.999996\n",
       "56656   2698500.0  697879.0  0.999997\n",
       "42212   3195000.0  697880.0  0.999999\n",
       "340170  3299995.0  697881.0  1.000000\n",
       "\n",
       "[697881 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['price', 'rank', 'rank_pct']].sort_values(by=['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_class_func(price):\n",
    "    if price >= .75:\n",
    "        return \"A\"\n",
    "    elif .5 <= price <= .74:\n",
    "        return \"B\"\n",
    "    elif .25 <= price <= .49:\n",
    "        return \"C\"\n",
    "    elif price <= .25:\n",
    "        return \"D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['price_cat']=df_test['rank_pct'].apply(apply_class_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_cat\n",
       "A    174898\n",
       "B    167554\n",
       "C    167491\n",
       "D    174472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby(['price_cat']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          price      rank  rank_pct price_cat\n",
      "0       14639.0  123784.0  0.177371         D\n",
      "1       32000.0  552264.0  0.791344         A\n",
      "2       23723.0  394672.0  0.565529         B\n",
      "3       22422.0  366562.0  0.525250         B\n",
      "4       29424.0  508197.5  0.728201         B\n",
      "...         ...       ...       ...       ...\n",
      "697984  17836.0  227445.0  0.325908         C\n",
      "697985  20700.0  324274.0  0.464655         C\n",
      "697986  17700.0  224104.0  0.321121         C\n",
      "697987  40993.0  643238.5  0.921702         A\n",
      "697988  19900.0  299409.0  0.429026         C\n",
      "\n",
      "[697881 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_test[['price', 'rank', 'rank_pct','price_cat']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Response Variable from Continuous to Categorical\n",
    "Since our main interest in this dataset is the 'price' of a vehicle, we will transform our continuous price attribute into a categorical one by grouping all car prices into the following:\n",
    "* \"<5000\"          : price < 5000\n",
    "* \"5000-10000\"     : 5000 <= price <= 10000\n",
    "* \"10000-15000\"    : 10000 < price <= 15000\n",
    "* \"15000-20000\"    : 15000 < price <= 20000\n",
    "* \"20000-25000\"    : 20000 < price <= 25000\n",
    "* \"25000 and over\" : price > 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_group = []\n",
    "for price in df_cleaned[\"price\"]:\n",
    "    if price < 5000:\n",
    "        price_group.append(\"<5000\")\n",
    "    elif 5000 <= price <= 10000:\n",
    "        price_group.append(\"5000-10000\")\n",
    "    elif 10000 < price <= 15000:\n",
    "        price_group.append(\"10000-15000\")\n",
    "    elif 15000 < price <= 20000:\n",
    "        price_group.append(\"15000-20000\")\n",
    "    elif 20000 < price <= 25000:\n",
    "        price_group.append(\"20000-25000\")\n",
    "    else:\n",
    "        price_group.append(\"25000 and over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            10000-15000\n",
      "1         25000 and over\n",
      "2            20000-25000\n",
      "3            20000-25000\n",
      "4         25000 and over\n",
      "               ...      \n",
      "697984       15000-20000\n",
      "697985       20000-25000\n",
      "697986       15000-20000\n",
      "697987    25000 and over\n",
      "697988       15000-20000\n",
      "Name: price_group, Length: 697881, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_price_group = df_cleaned.copy()\n",
    "df_price_group[\"price_group\"] = price_group\n",
    "del df_price_group[\"price\"]\n",
    "print(df_price_group['price_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_group\n",
       "10000-15000        96001\n",
       "15000-20000       172368\n",
       "20000-25000       115254\n",
       "25000 and over    268595\n",
       "5000-10000         40482\n",
       "<5000               5181\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price_group.groupby(['price_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoding\n",
    "Once the data has been imported and cleaned, we will work on transforming our dataset to be more useful for our classification models. To start we will first one-hot encode all of our categorical (object) datatypes as numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_encode_features(df_price_group):\n",
    "    result = df_price_group.copy()\n",
    "    encoders = {}\n",
    "    for column in result.columns:\n",
    "        if result.dtypes[column] == np.object or result.dtypes[column]==np.bool:\n",
    "            encoders[column] = preprocessing.LabelEncoder()\n",
    "            result[column] = encoders[column].fit_transform(result[column])\n",
    "    print('Columns converted: '+str(encoders))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows a snap shot of what the final data looks like after categorical data has been encoded.\n",
    "You can see the body type is in a numerical representation, instead of a string (object) type, before being encoded.\n",
    "<br>\n",
    "- Below shows a snap shot of what the final data looks like after categorical data has been encoded.\n",
    "- You can see the body type is in a numerical representation, instead of a string (object) type, before being encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns converted: {'body_type': LabelEncoder(), 'frame_damaged': LabelEncoder(), 'has_accidents': LabelEncoder(), 'is_new': LabelEncoder(), 'price_group': LabelEncoder()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_type</th>\n",
       "      <th>city_fuel_economy</th>\n",
       "      <th>daysonmarket</th>\n",
       "      <th>engine_displacement</th>\n",
       "      <th>frame_damaged</th>\n",
       "      <th>has_accidents</th>\n",
       "      <th>height</th>\n",
       "      <th>highway_fuel_economy</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>is_new</th>\n",
       "      <th>length</th>\n",
       "      <th>maximum_seating</th>\n",
       "      <th>mileage</th>\n",
       "      <th>owner_count</th>\n",
       "      <th>seller_rating</th>\n",
       "      <th>width</th>\n",
       "      <th>year</th>\n",
       "      <th>price_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>27.0</td>\n",
       "      <td>55</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42394.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.447761</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62251.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>81.5</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36410.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.447761</td>\n",
       "      <td>78.6</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36055.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.447761</td>\n",
       "      <td>78.5</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25745.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.447761</td>\n",
       "      <td>84.8</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697984</th>\n",
       "      <td>5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>69.9</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697985</th>\n",
       "      <td>5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697986</th>\n",
       "      <td>6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>37.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62138.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697987</th>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>89</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>75.2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697988</th>\n",
       "      <td>5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>72.4</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697881 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        body_type  city_fuel_economy  daysonmarket  engine_displacement  \\\n",
       "0               6               27.0            55               1500.0   \n",
       "1               1               18.0            36               3500.0   \n",
       "2               5               18.0            27               3600.0   \n",
       "3               5               15.0            27               3600.0   \n",
       "4               5               18.0            24               3600.0   \n",
       "...           ...                ...           ...                  ...   \n",
       "697984          5               26.0            32               1400.0   \n",
       "697985          5               26.0            17               2500.0   \n",
       "697986          6               26.0            17               2500.0   \n",
       "697987          4               18.0            89               3500.0   \n",
       "697988          5               26.0            17               2500.0   \n",
       "\n",
       "        frame_damaged  has_accidents  height  highway_fuel_economy  \\\n",
       "0                   0              0    57.6                  36.0   \n",
       "1                   0              0    55.1                  24.0   \n",
       "2                   0              0    70.7                  27.0   \n",
       "3                   0              1    69.9                  22.0   \n",
       "4                   0              0    69.3                  25.0   \n",
       "...               ...            ...     ...                   ...   \n",
       "697984              0              0    66.0                  31.0   \n",
       "697985              0              0    66.4                  32.0   \n",
       "697986              0              0    57.9                  37.0   \n",
       "697987              0              0    70.6                  23.0   \n",
       "697988              0              0    68.1                  33.0   \n",
       "\n",
       "        horsepower  is_new  length  maximum_seating  mileage  owner_count  \\\n",
       "0            160.0       0    57.6              5.0  42394.0          1.0   \n",
       "1            311.0       0    55.1              4.0  62251.0          1.0   \n",
       "2            310.0       0    70.7              8.0  36410.0          1.0   \n",
       "3            281.0       0    69.9              8.0  36055.0          1.0   \n",
       "4            295.0       0    69.3              5.0  25745.0          1.0   \n",
       "...            ...     ...     ...              ...      ...          ...   \n",
       "697984       138.0       0    66.0              5.0   7444.0          1.0   \n",
       "697985       170.0       0    66.4              5.0  20160.0          1.0   \n",
       "697986       179.0       0    57.9              5.0  62138.0          1.0   \n",
       "697987       278.0       0    70.6              5.0  20009.0          1.0   \n",
       "697988       170.0       0    68.1              7.0  22600.0          1.0   \n",
       "\n",
       "        seller_rating  width  year  price_group  \n",
       "0            3.447761   73.0  2018            0  \n",
       "1            2.800000   81.5  2018            3  \n",
       "2            3.447761   78.6  2018            2  \n",
       "3            3.447761   78.5  2017            2  \n",
       "4            3.447761   84.8  2018            3  \n",
       "...               ...    ...   ...          ...  \n",
       "697984       4.533333   69.9  2019            1  \n",
       "697985       4.333333   80.0  2017            2  \n",
       "697986       4.333333   72.0  2018            1  \n",
       "697987       5.000000   75.2  2017            3  \n",
       "697988       4.333333   72.4  2017            1  \n",
       "\n",
       "[697881 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = number_encode_features(df_price_group)\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referncing our transformed variable 'price_group' as an int to it's original string value for future analysis and interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_group\n",
      "0     96001\n",
      "1    172368\n",
      "2    115254\n",
      "3    268595\n",
      "4     40482\n",
      "5      5181\n",
      "dtype: int64\n",
      "-----------------------------------------\n",
      "price_group\n",
      "10000-15000        96001\n",
      "15000-20000       172368\n",
      "20000-25000       115254\n",
      "25000 and over    268595\n",
      "5000-10000         40482\n",
      "<5000               5181\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_final.groupby(['price_group']).size())\n",
    "print('-----------------------------------------')\n",
    "print(df_price_group.groupby(['price_group']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready for some model building!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Records: 697881\n",
      "# of Columns: 18\n",
      "\n",
      "body_type                 int32\n",
      "city_fuel_economy       float64\n",
      "daysonmarket              int64\n",
      "engine_displacement     float64\n",
      "frame_damaged             int64\n",
      "has_accidents             int64\n",
      "height                  float64\n",
      "highway_fuel_economy    float64\n",
      "horsepower              float64\n",
      "is_new                    int64\n",
      "length                  float64\n",
      "maximum_seating         float64\n",
      "mileage                 float64\n",
      "owner_count             float64\n",
      "seller_rating           float64\n",
      "width                   float64\n",
      "year                      int64\n",
      "price_group               int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_final = encoded_data.copy()\n",
    "print('# of Records: '+str(len(df_final)))\n",
    "print('# of Columns: '+str(df_final.shape[1]))\n",
    "print()\n",
    "print(df_final.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Split\n",
    "Once our dataset ready for modeling, we will move on to our next steps of splitting up our data. For our dataset, we will use a 70:30 split that roughly leaves our training set with 488k records and test set with the remainder (209k records). We will then apply a 3-fold Cross Validation with a seed of 42 because it (42) is the answer to the ultimate question of life, the universe, and everything.\n",
    "<br><br>\n",
    "Our resposne variable will be price, more specifically the price group ('price_group') a car falls in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 2 ... 1 3 1]\n",
      "\n",
      "ShuffleSplit(n_splits=3, random_state=42, test_size=0.3, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "if 'price_group' in df_final:\n",
    "    y = df_final['price_group'].values # get the labels we want\n",
    "    del df_final['price_group'] # get rid of the class label\n",
    "    X = df_final.values # use everything else to predict!\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,random_state=42, test_size= 0.3)     \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Training Set: 488516\n",
      "Count of Test Set: 209365\n"
     ]
    }
   ],
   "source": [
    "print('Count of Training Set: '+str(len(train_indices)))\n",
    "print('Count of Test Set: '+ str(len(test_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None, solver='liblinear' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.5940104602010843\n",
      "confusion matrix\n",
      " [[ 8282 17791     4  1384  1359     0]\n",
      " [ 2907 37266     1 11376   278     1]\n",
      " [  544 17526     7 16295    70     2]\n",
      " [  163  6378     2 74023    14     3]\n",
      " [ 4853  2435     0    69  4786     0]\n",
      " [   74    59     0     2  1410     1]]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.5931268359085807\n",
      "confusion matrix\n",
      " [[ 8003 17858     2  1482  1220     2]\n",
      " [ 2751 37299     1 11422   272     0]\n",
      " [  490 17589     1 16732    59     2]\n",
      " [  180  6272     1 74079    19     2]\n",
      " [ 4884  2305     0    81  4793     7]\n",
      " [   82    32     0     2  1436     5]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.5915076540969121\n",
      "confusion matrix\n",
      " [[ 7979 18043     9  1418  1275     3]\n",
      " [ 2804 37257    24 11597   260     2]\n",
      " [  542 17366    11 16641    77     4]\n",
      " [  210  6342     1 73901    21     2]\n",
      " [ 4790  2460     0    76  4692     5]\n",
      " [   67    66     0     0  1419     1]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722f213c7ffe4cad93cc20d7e086bede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.451, description='cost', max=5.0, min=0.001, step=0.05), Output()), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.lr_explor(cost)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we can change some of the parameters interactively\n",
    "from ipywidgets import widgets as wd\n",
    "\n",
    "def lr_explor(cost):\n",
    "    lr_clf = LogisticRegression(penalty='l2', C=cost, class_weight=None,solver='liblinear') # get object\n",
    "    accuracies = cross_val_score(lr_clf,X,y=y,cv=cv_object) # this also can help with parallelism\n",
    "    print(accuracies)\n",
    "\n",
    "wd.interact(lr_explor,cost=(0.001,5.0,0.05),__manual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR - Analysis & Intepretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weights *before* normalization:**\n",
    "<br>\n",
    "We can see that even before we normalized our dataset the **'mileage'** and **'frame_damaged'** attribute showns an extremely strong weight in regards to the price (and group) of a vehicle. Additionally, we can see that **'is_new'** has a particularly strong negative weight in regards to price, this can be interpreted that this variable less of an effect on pricing, which makes sense since prior analysis (lab 1) showed us that 99% of our data is used cars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_type has weight of 0.0057163416525310715\n",
      "city_fuel_economy has weight of 0.008468206076927606\n",
      "daysonmarket has weight of 0.00026206704928768027\n",
      "engine_displacement has weight of 0.00016257524473640075\n",
      "frame_damaged has weight of 3.420932842151794e-05\n",
      "has_accidents has weight of 0.0009125828229602852\n",
      "height has weight of -0.02536604331004255\n",
      "highway_fuel_economy has weight of 0.033091731256355165\n",
      "horsepower has weight of -0.010847141122508433\n",
      "is_new has weight of -2.3644937572113936e-05\n",
      "length has weight of -0.02536604331004255\n",
      "maximum_seating has weight of 0.00043665006943592\n",
      "mileage has weight of 2.088535312684802e-05\n",
      "owner_count has weight of 0.0036910533862481074\n",
      "seller_rating has weight of -0.0013893811373334307\n",
      "width has weight of 0.0004954509109703305\n",
      "year has weight of 0.00047962953048214706\n"
     ]
    }
   ],
   "source": [
    "weights = lr_clf.coef_.T # take transpose to make a column vector\n",
    "variable_names = df_final.columns\n",
    "for coef, name in zip(weights,variable_names):\n",
    "    print(name, 'has weight of', coef[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weights *after* normalization:**\n",
    "<br>\n",
    "Once the weights have been normalized as shown below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6145726363050176\n",
      "[[10011 16281   116   763  1556     0]\n",
      " [ 3074 37840   398 10404   228     0]\n",
      " [  474 17375   221 16531    40     0]\n",
      " [  123  5677    58 74573    46     0]\n",
      " [ 4485  1493     5    15  6025     0]\n",
      " [   27     0     0     0  1526     0]]\n"
     ]
    }
   ],
   "source": [
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05, solver='liblinear') # get object, the 'C' value is less (can you guess why??)\n",
    "lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_type has weight of 0.0866878246447711\n",
      "city_fuel_economy has weight of -0.6396807600296892\n",
      "daysonmarket has weight of 0.0101849650015951\n",
      "engine_displacement has weight of 0.08583712950560271\n",
      "frame_damaged has weight of 0.0006613351249991328\n",
      "has_accidents has weight of 0.04001650928425897\n",
      "height has weight of 0.008054892005808624\n",
      "highway_fuel_economy has weight of 1.0301979658227287\n",
      "horsepower has weight of -0.9231363777396635\n",
      "is_new has weight of -0.07040009675626192\n",
      "length has weight of 0.008054892005808624\n",
      "maximum_seating has weight of 0.04903695769244853\n",
      "mileage has weight of 0.6221085747978092\n",
      "owner_count has weight of 0.1103811763580796\n",
      "seller_rating has weight of -0.06270892693260087\n",
      "width has weight of 0.005805976522987003\n",
      "year has weight of -0.09235570878852435\n"
     ]
    }
   ],
   "source": [
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(lr_clf.coef_.T,df_final.columns) # combine attributes\n",
    "#zip_vars = sorted(zip_vars) this does not work since our expected value has 6 distinct groups\n",
    "\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 1, 4, 5])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['price_group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.66878246e-02 -5.51634477e-02 -4.56715886e-02  2.33739202e-01\n",
      "  -3.23264860e-02  7.72698416e-02]\n",
      " [-6.39680760e-01 -1.26097880e-01 -4.16812617e-01  1.45538110e+00\n",
      "  -1.20765966e+00 -8.13981633e-01]\n",
      " [ 1.01849650e-02  2.67397531e-02 -6.11713637e-03 -1.40204270e-01\n",
      "  -4.04370053e-02  1.13942763e-02]\n",
      " [ 8.58371295e-02  2.96728489e-01 -1.93977906e-01 -6.96789975e-02\n",
      "  -5.92580017e-01 -2.86843352e-01]\n",
      " [ 6.61335125e-04 -6.74923642e-03 -1.01112131e-02 -3.74842466e-02\n",
      "   1.55108949e-02  3.80139433e-02]\n",
      " [ 4.00165093e-02  5.17606828e-03  6.11150995e-03 -6.27312332e-02\n",
      "   7.24584694e-02  3.84751321e-02]\n",
      " [ 8.05489201e-03 -1.55734915e-01 -1.76206881e-02  2.17536895e-01\n",
      "  -2.45435960e-02 -2.62414574e-01]\n",
      " [ 1.03019797e+00 -3.94768002e-02 -5.62937006e-02 -1.18517244e+00\n",
      "   1.30244527e+00  3.06951730e-01]\n",
      " [-9.23136378e-01 -1.33516862e+00 -4.22892068e-01  2.99399453e+00\n",
      "  -9.81584455e-01 -1.37099271e+00]\n",
      " [-7.04000968e-02 -4.64597708e-02 -2.60674750e-02  4.45396976e-02\n",
      "  -5.74705922e-02  4.63309689e-02]\n",
      " [ 8.05489201e-03 -1.55734915e-01 -1.76206881e-02  2.17536895e-01\n",
      "  -2.45435960e-02 -2.62414574e-01]\n",
      " [ 4.90369577e-02  7.14162086e-02 -8.68611553e-02 -1.04279093e-01\n",
      "   1.67615611e-01  4.52653250e-01]\n",
      " [ 6.22108575e-01  2.52430374e-02 -2.21839373e-01 -1.69314803e+00\n",
      "   1.01616427e+00  9.19887805e-01]\n",
      " [ 1.10381176e-01 -3.18439387e-02 -3.27881811e-02 -9.14079969e-02\n",
      "   4.20049733e-02  1.42881038e-01]\n",
      " [-6.27089269e-02 -2.98035430e-02 -1.36039825e-02  1.68928386e-01\n",
      "  -4.40187948e-02 -1.18704211e-01]\n",
      " [ 5.80597652e-03  1.49848965e-01 -1.69810694e-02  2.06493567e-01\n",
      "  -2.40759709e-02 -4.95586993e-02]\n",
      " [-9.23557088e-02  2.43165593e-01  2.98270626e-01  8.30465539e-01\n",
      "  -9.54756210e-01 -8.57568999e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(lr_clf.coef_.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
